#global imports
import matplotlib as plt
import numpy as np
import tensorflow.keras.datasets.mnist as mnist
from tensorflow.keras import utils
from tensorflow.keras import models
import matplotlib.pyplot  as plt

#local imports
from models import CNN_model, PCA_model
from attack_tests import *
from img_manipulations import *
from database_manipulations import *


#CONSTANTS
MAX_BLUR = 2



#Load the main MNIST Dataset 
(x_train, y_train), (x_test, y_test) = mnist.load_data()  
x_train = x_train / 255  
x_test = x_test / 255

#get categorical versions of the labels
y_train_cat = utils.to_categorical(y_train, 10)
y_test_cat = utils.to_categorical(y_test, 10)

#special version of dataset for rotations
rx_train, ry_train = prep_rotations(x_train, y_train)
rx_test, ry_test = prep_rotations(x_test, y_test)

#get categorical versions of the rotation-ready labels
ry_train_cat = utils.to_categorical(ry_train, 10)
ry_test_cat = utils.to_categorical(ry_test, 10)



""" PCA Model Training Code (250 components)

pca_model = PCA_model(250, 10)

lattice = attack_lattice(PCA_model, (x_train, y_train_cat), (x_test, y_test_cat), gaussian_blur_database, np.arange(0, 2, 0.1))

np.savetxt("pca_gauss_lattice.txt", lattice)


pca_model = PCA_model(250, 10)
pca_model.fit(x_train, y_train_cat)
pca_model.save("pca_weights")
"""

""" DNN Model Training Code
dnn_model = PCA_model(28*28, 10, True, False)
dnn_model.fit(x_train, y_train_cat)
dnn_model.save("dnn_weights")
"""

""" CNN Model Training Code
cnn_model.fit(x_train.reshape(-1, 28, 28, 1), one_hot_encode(y_train))
cnn_model.save_weights('cnn_weights')
"""

#setting up the model to test
rotation_steps = list(range(0, 181, 10))

for rot in rotation_steps[2:]:
    rx_train_new = rotate_database(rx_train, 0, rot)
    
    cnn_model = CNN_model()
    cnn_model.fit(rx_train_new.reshape(-1, 28, 28, 1), ry_train_cat)
    
    
    #testing
    accs = []
    for rotation_step in rotation_steps:
        rx_test_new = rotate_database(rx_test, 0, rotation_step)
        cur_acc = cnn_model.evaluate(rx_test_new, ry_test_cat)[1]
        accs.append(cur_acc)
        
    
    #store accs in a text file
    with open("cnn_accs.txt", "a") as file:
        file.write(str(accs) + ",\n")



#plotting
# rotation_steps = list(range(0, 181, 10))
# accuracy_matrix = np.array([
#     [0.9859330058097839, 0.9812025427818298, 0.9688783884048462, 0.9309099912643433, 0.8706585168838501, 0.7973359823226929, 0.7257562279701233, 0.6362504959106445, 0.5910618901252747, 0.5326777100563049, 0.5028009414672852, 0.4691895842552185, 0.4429229497909546, 0.41466450691223145, 0.421760231256485, 0.4167807698249817, 0.4125482439994812, 0.41454002261161804, 0.40956056118011475],
#     [0.9258060455322266, 0.9229428768157959, 0.9164695739746094, 0.8928171396255493, 0.8438939452171326, 0.7797833681106567, 0.7007344961166382, 0.6459603905677795, 0.5918087959289551, 0.5450018644332886, 0.5093987584114075, 0.4726752042770386, 0.45064109563827515, 0.433586448431015, 0.41877254843711853, 0.41429105401039124, 0.41454002261161804, 0.40520352125167847, 0.41080543398857117],
#     [0.9524461627006531, 0.9516992568969727, 0.951201319694519, 0.9452259540557861, 0.9144777655601501, 0.875389039516449, 0.816133439540863, 0.7571268677711487, 0.7024772763252258, 0.6419768333435059, 0.6005228161811829, 0.5667870044708252, 0.5397734642028809, 0.5121374130249023, 0.49296650290489197, 0.48823603987693787, 0.47815263271331787, 0.4696875512599945, 0.4688161313533783],
#     [0.9794597029685974, 0.9778413772583008, 0.9772189855575562, 0.9737333655357361, 0.9676334857940674, 0.9474666714668274, 0.9099962711334229, 0.8519855737686157, 0.7800323367118835, 0.7242624163627625, 0.6759616732597351, 0.6362504959106445, 0.5980331301689148, 0.5698991417884827, 0.557450532913208, 0.5562056303024292, 0.5529689788818359, 0.5323042273521423, 0.5357898473739624],
#     [0.9769700169563293, 0.9769700169563293, 0.9751027226448059, 0.9770944714546204, 0.97149258852005, 0.9622805714607239, 0.938254714012146, 0.8959292769432068, 0.8329391479492188, 0.7842649221420288, 0.7323540449142456, 0.6879123449325562, 0.6515623331069946, 0.627660870552063, 0.6229304075241089, 0.5951699018478394, 0.579982578754425, 0.5741317272186279, 0.5680318474769592],
#     [0.8989169597625732, 0.9005352854728699, 0.8991659283638, 0.9070085883140564, 0.9048923254013062, 0.8959292769432068, 0.8913232684135437, 0.8746420741081238, 0.848002016544342, 0.8110294938087463, 0.7683306336402893, 0.7167932391166687, 0.689281702041626, 0.652309238910675, 0.6317689418792725, 0.6118510961532593, 0.596663773059845, 0.5863313674926758, 0.5711440443992615],
#     [0.8600772023200989, 0.8600772023200989, 0.8600772023200989, 0.857711911201477, 0.8614465594291687, 0.8553466796875, 0.852981448173523, 0.8440183997154236, 0.8186231851577759, 0.7855097651481628, 0.7428109049797058, 0.7136810421943665, 0.6799452304840088, 0.6473297476768494, 0.6172040104866028, 0.6081165075302124, 0.5803560018539429, 0.5806050300598145, 0.5621809959411621],
#     [0.9580480456352234, 0.9587949514389038, 0.9592928886413574, 0.9565542340278625, 0.9581725597381592, 0.9582970142364502, 0.957425594329834, 0.9568032026290894, 0.951201319694519, 0.9388771057128906, 0.905141294002533, 0.8791236281394958, 0.8447653651237488, 0.8082907795906067, 0.7809037566184998, 0.7588696479797363, 0.731856107711792, 0.714054524898529, 0.6957550048828125],
#     [0.9671355485916138, 0.966762125492096, 0.9672600626945496, 0.9637744426727295, 0.9656417369842529, 0.9653927683830261, 0.9651437997817993, 0.9660151600837708, 0.9655172228813171, 0.9610357284545898, 0.9427362084388733, 0.9230673313140869, 0.8893315196037292, 0.8592057824134827, 0.8224822878837585, 0.8038092851638794, 0.7669612765312195, 0.7528942823410034, 0.7321050763130188] ,
#     [0.9447280168533325, 0.9424872398376465, 0.9457238912582397, 0.9451014399528503, 0.9494584798812866, 0.9497074484825134, 0.9519482254981995, 0.9540644884109497, 0.9550603628158569, 0.9505788683891296, 0.9439810514450073, 0.9312834739685059, 0.9094983339309692, 0.8785011768341064, 0.8536038994789124, 0.8277106881141663, 0.7906137108802795, 0.7695754766464233, 0.7490352392196655],
#     [0.9411178827285767, 0.9414913654327393, 0.9462218284606934, 0.9449769854545593, 0.9451014399528503, 0.947715699672699, 0.9488360285758972, 0.9509523510932922, 0.948960542678833, 0.9523216485977173, 0.9521971940994263, 0.9485870599746704, 0.9355159997940063, 0.9132329225540161, 0.8799950480461121, 0.8594547510147095, 0.8303248882293701, 0.8075438737869263, 0.7807793021202087],
#     [0.899041473865509, 0.8960537910461426, 0.8903273940086365, 0.8914477825164795, 0.8822357654571533, 0.8783767223358154, 0.8664259910583496, 0.8625668883323669, 0.8558446168899536, 0.8629403710365295, 0.8613220453262329, 0.854226291179657, 0.8536038994789124, 0.8437694311141968, 0.8163824081420898, 0.7887464165687561, 0.76285320520401, 0.741441547870636, 0.7048425078392029],
#     [0.9508278369903564, 0.9525706171989441, 0.9493340253829956, 0.9459728598594666, 0.9472177028656006, 0.9411178827285767, 0.9426117539405823, 0.9444790482521057, 0.9401220083236694, 0.9451014399528503, 0.9433586597442627, 0.9454749226570129, 0.9470932483673096, 0.938379168510437, 0.9314079284667969, 0.9121125340461731, 0.8853479623794556, 0.8582099080085754, 0.8275862336158752],
#     [0.9637744426727295, 0.96302753   68690491, 0.9614092111587524, 0.9606622457504272, 0.9580480456352234, 0.9590439200401306, 0.957425594329834, 0.9589194655418396, 0.9549359083175659, 0.9569276571273804, 0.958545982837677, 0.9582970142364502, 0.9565542340278625, 0.9555583000183105, 0.9497074484825134, 0.9351425170898438, 0.9155981540679932, 0.8794970512390137, 0.8547242879867554],
#     [0.9357649683952332, 0.9365118741989136, 0.9381301999092102, 0.9404954314231873, 0.937134325504303, 0.9421137571334839, 0.9398730397224426, 0.9429851770401001, 0.9447280168533325, 0.9472177028656006, 0.9436076283454895, 0.9441055655479431, 0.9508278369903564, 0.9482136368751526, 0.9498319625854492, 0.9460973739624023, 0.9355159997940063, 0.9218224883079529, 0.8992904424667358],
#     [0.937134325504303, 0.9366363883018494, 0.9352670311927795, 0.9350180625915527, 0.9291672110557556, 0.927548885345459, 0.9216979742050171, 0.9183368682861328, 0.9111166596412659, 0.9047678112983704, 0.9024025797843933, 0.9032739996910095, 0.907382071018219, 0.9007842540740967, 0.9022781252861023, 0.9029005169868469, 0.9048923254013062, 0.8963027596473694, 0.8826092481613159],
#     [0.7587451934814453, 0.7655919194221497, 0.7720652222633362, 0.7933524250984192, 0.8080418109893799, 0.825594425201416, 0.8371716737747192, 0.8430225253105164, 0.8499937653541565, 0.856467068195343, 0.8562180995941162, 0.8628158569335938, 0.86368727684021, 0.86717289686203, 0.86368727684021, 0.8531059622764587, 0.8562180995941162, 0.8410307765007019, 0.8223577737808228],
#     [0.951201319694519, 0.9508278369903564, 0.9519482254981995, 0.9487115740776062, 0.9470932483673096, 0.9458483457565308, 0.9449769854545593, 0.9459728598594666, 0.9448524713516235, 0.9448524713516235, 0.9474666714668274, 0.9422382712364197, 0.9459728598594666, 0.9487115740776062, 0.9458483457565308, 0.9475911855697632, 0.9484626054763794, 0.9485870599746704, 0.9462218284606934],
#     [0.9494584798812866, 0.9508278369903564, 0.9541889429092407, 0.9533175826072693, 0.9536910057067871, 0.9523216485977173, 0.9538155198097229, 0.9519482254981995, 0.9528196454048157, 0.9508278369903564, 0.9508278369903564, 0.9535665512084961, 0.9503298997879028, 0.951201319694519, 0.9545624256134033, 0.9529440999031067, 0.9526951313018799, 0.9533175826072693, 0.9529440999031067]

#     ])

# fig, ax = plt.subplots()
# c = ax.pcolormesh(rotation_steps, rotation_steps, accuracy_matrix.T, cmap='RdBu')
# ax.set_title("Accuracy on rotated images, depending on rotation of the training dataset")
# plt.xlabel("Rotation max of the training dataset")
# plt.ylabel("Rotation max of the testing sample")
# plt.show()




#list of all the training data set rotation values
# training_database= rotate_database(rx_train, 0, rotation_steps[1])



#loading the models from memory
# pca_model = PCA_model.load("pca_weights") 
# dnn_model = PCA_model.load("dnn_weights") 

# cnn_model = CNN_model()
# cnn_model.load_weights('cnn_weights')



#BOILERPLATE code for generating and plotting the effect of an attack
# n_samples = 8
attack_func = perlin_noise_database




# arguments = np.array(  [[i/10] for i in range(8)] )
# # arguments[:, 0] = [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5]
# # arguments[:, 1] = arguments[:, 0]



# model_list = [pca_model, dnn_model, cnn_model]


attack_range = np.linspace(0, 0.7, 10)

lattice = attack_lattice(CNN_model, (x_train, y_train_cat), (x_test, y_test_cat), attack_func, attack_range)

plt.pcolormesh(lattice, cmap='vridis')
plt.show()


np.savetxt('lattice_perlin_cnn', lattice)

# result = run_attacks(x_test, y_test_cat, model_list, attack_function, arguments)


# plt.plot(x_axis, result[0], label="PCA Model")
# plt.plot(x_axis, result[1], label="DNN Model")
# plt.plot(x_axis, result[2], label="CNN Model")
# plt.legend(loc="upper right")
# plt.xlabel("Maximum perlin noise level allowed (1 = 100%)")
# plt.ylabel("Accuracy of models")


# plt.show()



# fig = plt.figure()
# noise_test = x_test[0]

# for i in range(25):
#     fig.add_subplot(5, 5, i+1)
#     plt.axis("off")
#     plt.imshow(flip_image(x_test[i]))
